---
title: "p8105_hw2_sq2266"
author: "Sihan Qiu"
output: github_document
---




```{r setup}
library(tidyverse)
library(readxl)
```

## Problem 1
```{r}
transit_df = 
  read_csv("NYC_Transit_Subway_Entrance_And_Exit_Data.csv",col_types = cols(Route8 = "c", Route9 = "c", Route10 = "c", Route11 = "c")) |>
  janitor::clean_names() |>
  select(
    line, station_name, station_latitude, station_longitude, 
    starts_with("route"), entry, exit_only, vending, entrance_type, 
    ada) |> 
  mutate(entry = case_match(
    entry,
    "YES" ~ "TRUE",
    "NO" ~ "FALSE"
  )
  )
print(transit_df)
```

## Trying to combine key variables
```{r}
 transit_df |> 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") |> 
  filter(route == "A") |> 
  select(station_name, line) |> 
  distinct()
```


Description: 
This dataset includes information of subway stations in New York City. Key variables includes `division`,`line`, `station_name`, `station_latitude`,`station_longitude`,`routes`, `entry`,`vending`,`entrance_type`, and `ada`. The data cleaning steps includes standardizing column names by using `janitor::clean_names` to make uppercase and lowercase separated, converting `entry` from a character variable to a logical variable. 




## Problem 2
### Cleaning and reading data
```{r}
mr_trash_df = 
  read_excel("202409 Trash Wheel Collection Data.new.xlsx", sheet = 1, skip = 1) |>
  janitor::clean_names() |>
  select(-x15, -x16) |>
  mutate(year=as.character(year)) |>
  mutate(sports_balls = as.integer(round(sports_balls,0))) |>
  mutate(trash_wheel = "Mr. Trash Wheel") |>
  filter(!is.na(dumpster)) |>
  relocate(trash_wheel) 
```

### Cleaning Professor Trash Wheel and Gwynnda
```{r}
prof_trash_df = 
  read_excel("202409 Trash Wheel Collection Data.new.xlsx", sheet = 2, na = c("NA",".",""),skip = 1) |>
  janitor::clean_names() |>
  mutate(trash_wheel = "Profesor Trash Wheel") |>
  mutate(year=as.character(year)) |>
  filter(!is.na(dumpster),!is.na(date)) |>
  relocate(trash_wheel)
```

```{r}
Gwy_trash_df = 
  read_excel("202409 Trash Wheel Collection Data.new.xlsx", sheet = 4,na = c("NA",".","")) |>
  janitor::clean_names() |>
  mutate(trash_wheel = "Gwynnda") |>
  mutate(year=as.character(year)) |>
  filter(!is.na(dumpster)) |>
  relocate(trash_wheel)
```

### Combining dataset
```{r}
total_trash_df = 
  bind_rows(mr_trash_df,prof_trash_df,Gwy_trash_df) |>
  janitor::clean_names()
```

### Data description

The dataset contains observations on `r nrow(total_trash_df)` three different datasets. The data includes `r ncol(total_trash_df)` variables, including month, year, different types of trash (plastic bottles, polystyrene, cigarette butts, glass bottle, plastic bags,wrappers,sports ball, and homes powered), also weight, and volume. The total weight of trash collected by Professor Trash Wheel is 246.74. The total number of cigarette butts collected by Gwynnda in June of 2022 is 18120.

### Calculation
```{r}
sum(pull(prof_trash_df,weight_tons),na.rm = TRUE)
```

```{r}
total_trash_df |>
  filter(trash_wheel == "Gwynnda", month == "June", year == "2022") |>
  summarise(total_cig_butts_Gwy = sum(cigarette_butts, na.rm = TRUE))
```



## Problem 3

### Importing three datasets
```{r}
bakers_df = 
  read_csv("gbb_datasets/bakers.csv", na = c("NA",".",""))|>
  janitor::clean_names()|>
  rename(name = baker_name) |>
  rename(age = baker_age) |>
  rename(occupation = baker_occupation) |>
  mutate(series = as.character(series)) |>
  mutate(first_name = word(name, 1))
```

```{r}
bakes_df = 
  read_csv("gbb_datasets/bakes.csv",na = c("NA",".","")) |>
  janitor::clean_names() |>
  mutate(baker = str_replace_all(baker, '"', "")) |>
  relocate(baker) |>
  rename(name = baker) |>
  rename(signature = signature_bake) |>
  mutate(series = as.character(series)) |>
  mutate(episode =as.character(episode))|>
  arrange(name)
```

```{r}
results_df = 
  read_csv("gbb_datasets/results.csv",na = c("NA",".",""),skip=2) |>
  janitor::clean_names() |>
  mutate(episode = as.character(episode))|>
  mutate(baker = str_replace_all(baker, "Joanne", "Jo")) |>
  rename(name = baker) |>
  mutate(series = as.character(series)) 
```

### Checking completness and correctness 
```{r}
missing_bakers_in_bake_df = 
  anti_join(bakers_df, bakes_df, by=c("first_name"="name","series"))
missing_brakers_in_results_df =
  anti_join(bakers_df, results_df, by=c("name","series"))
```

### Merging datasets
```{r}
merged_df = 
  bakers_df |>
  left_join(results_df, by = c("first_name"="name", "series")) |>
  left_join(bakes_df, by = c("first_name" = "name", "series", 
                               "episode"))
write.csv(merged_df,"merged_cleaned_result.csv",row.names = FALSE )
```

Description:
I first imported three datasets. First i imported the baker.csv from the working directory "gbb_datasets", and treated the values "NA", ".", and "" as missing data (NA values). I used janitor::clean_names to clean the column names by converting them to snake_case, making them lowercase, and removing special characters or spaces. Then I rename baker_name to name, baker_age to age, baker_occupation to occupation which helps me to understand. Because in the original dataset, series is a double variable, so i converted it into character variable. I also created a new column "first_name". I used word function to extract the first row from the name. 

Then i imported the bakes.csv from the working directory "gbb_datasets", and treated the values "NA", ".", and "" as missing data (NA values). I used janitor::clean_names to clean the column names by converting them to snake_case, making them lowercase, and removing special characters or spaces. Then I modify baker column to replace all occurrences of the double quote variables, and remove it to the first row. I rename name and signature variables, and converted series and episode into character variables. Then making name alphabetically. I converted variables because I met problems when I first try to merge without converting them into same level. 

I used the same way to clean the results.csv. One different was that I used mutate function to people who named "Joanne" with "Jo". 

I used left_join to merge three dataset by matching "first name" with "name","series" with "series", "episode" with "episode". Then I used write.csv to import the table. In the final dataset, it contains observation `r nrow(merged_df)` with `r ncol(merged_df)` columns. Bakers' name are in alphabetical order. Key variables are hometown, series, episode, occupation, signature, and their final result (in or out of the competition). 


### Create a reader-friendly table
```{r}
star_bakers_df = 
  merged_df |>
  filter(series >= 5) |>
  filter(result %in% c("WINNER","STAR BAKER")) |>
  select(name, series, episode, result)
```
Comments:
Candince is not a surprising winner. She showed up on 10 episode in series 7, which means she is very good/talented at baking. Nadiya is also a predictable winner because she showed up 9 episodes in series 6, as well as Sophie. Rahul gives surprise because he does not show up as much as other winners do. 


### Importing viewer.csv
```{r}
viewer_df = 
  read_csv("gbb_datasets/viewers.csv",na = c("NA",".","")) |>
  janitor::clean_names() |>
  pivot_longer(
    series_1:series_10,
    names_to = "series",
    values_to = "viewship") |>
    head(10)
```


```{r}
view_df = 
  read_csv("gbb_datasets/viewers.csv",na = c("NA",".","")) |>
  janitor::clean_names()
  mean(pull(view_df,"series_1"),na.rm = TRUE) 
  mean(pull(view_df,"series_5"),na.rm = TRUE) 
```

The average viewership in Season 1 is 2.77, Season 5 is 10.0393.
