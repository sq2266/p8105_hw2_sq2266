p8105_hw2_sq2266
================
Sihan Qiu

``` r
library(tidyverse)
```

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.4     ✔ readr     2.1.5
    ## ✔ forcats   1.0.0     ✔ stringr   1.5.1
    ## ✔ ggplot2   3.5.1     ✔ tibble    3.2.1
    ## ✔ lubridate 1.9.3     ✔ tidyr     1.3.1
    ## ✔ purrr     1.0.2     
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

``` r
library(readxl)
```

## Problem 1

``` r
transit_df = 
  read_csv("NYC_Transit_Subway_Entrance_And_Exit_Data.csv",col_types = cols(Route8 = "c", Route9 = "c", Route10 = "c", Route11 = "c")) |>
  janitor::clean_names() |>
  select(
    line, station_name, station_latitude, station_longitude, 
    starts_with("route"), entry, exit_only, vending, entrance_type, 
    ada) |> 
  mutate(entry = case_match(
    entry,
    "YES" ~ "TRUE",
    "NO" ~ "FALSE"
  )
  )
print(transit_df)
```

    ## # A tibble: 1,868 × 20
    ##    line     station_name station_latitude station_longitude route1 route2 route3
    ##    <chr>    <chr>                   <dbl>             <dbl> <chr>  <chr>  <chr> 
    ##  1 4 Avenue 25th St                  40.7             -74.0 R      <NA>   <NA>  
    ##  2 4 Avenue 25th St                  40.7             -74.0 R      <NA>   <NA>  
    ##  3 4 Avenue 36th St                  40.7             -74.0 N      R      <NA>  
    ##  4 4 Avenue 36th St                  40.7             -74.0 N      R      <NA>  
    ##  5 4 Avenue 36th St                  40.7             -74.0 N      R      <NA>  
    ##  6 4 Avenue 45th St                  40.6             -74.0 R      <NA>   <NA>  
    ##  7 4 Avenue 45th St                  40.6             -74.0 R      <NA>   <NA>  
    ##  8 4 Avenue 45th St                  40.6             -74.0 R      <NA>   <NA>  
    ##  9 4 Avenue 45th St                  40.6             -74.0 R      <NA>   <NA>  
    ## 10 4 Avenue 53rd St                  40.6             -74.0 R      <NA>   <NA>  
    ## # ℹ 1,858 more rows
    ## # ℹ 13 more variables: route4 <chr>, route5 <chr>, route6 <chr>, route7 <chr>,
    ## #   route8 <chr>, route9 <chr>, route10 <chr>, route11 <chr>, entry <chr>,
    ## #   exit_only <chr>, vending <chr>, entrance_type <chr>, ada <lgl>

## Trying to combine key variables

``` r
 transit_df |> 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") |> 
  filter(route == "A") |> 
  select(station_name, line) |> 
  distinct()
```

    ## # A tibble: 60 × 2
    ##    station_name                  line           
    ##    <chr>                         <chr>          
    ##  1 Times Square                  42nd St Shuttle
    ##  2 125th St                      8 Avenue       
    ##  3 145th St                      8 Avenue       
    ##  4 14th St                       8 Avenue       
    ##  5 168th St - Washington Heights 8 Avenue       
    ##  6 175th St                      8 Avenue       
    ##  7 181st St                      8 Avenue       
    ##  8 190th St                      8 Avenue       
    ##  9 34th St                       8 Avenue       
    ## 10 42nd St                       8 Avenue       
    ## # ℹ 50 more rows

Description: This dataset includes information of subway stations in New
York City. Key variables includes `division`,`line`, `station_name`,
`station_latitude`,`station_longitude`,`routes`,
`entry`,`vending`,`entrance_type`, and `ada`. The data cleaning steps
includes standardizing column names by using `janitor::clean_names` to
make uppercase and lowercase separated, converting `entry` from a
character variable to a logical variable.

## Problem 2

### Cleaning and reading data

``` r
mr_trash_df = 
  read_excel("202409 Trash Wheel Collection Data.new.xlsx", sheet = 1, skip = 1) |>
  janitor::clean_names() |>
  select(-x15, -x16) |>
  mutate(year=as.character(year)) |>
  mutate(sports_balls = as.integer(round(sports_balls,0))) |>
  mutate(trash_wheel = "Mr. Trash Wheel") |>
  filter(!is.na(dumpster)) |>
  relocate(trash_wheel) 
```

    ## New names:
    ## • `` -> `...15`
    ## • `` -> `...16`

### Cleaning Professor Trash Wheel and Gwynnda

``` r
prof_trash_df = 
  read_excel("202409 Trash Wheel Collection Data.new.xlsx", sheet = 2, na = c("NA",".",""),skip = 1) |>
  janitor::clean_names() |>
  mutate(trash_wheel = "Profesor Trash Wheel") |>
  mutate(year=as.character(year)) |>
  filter(!is.na(dumpster),!is.na(date)) |>
  relocate(trash_wheel)
```

``` r
Gwy_trash_df = 
  read_excel("202409 Trash Wheel Collection Data.new.xlsx", sheet = 4,na = c("NA",".","")) |>
  janitor::clean_names() |>
  mutate(trash_wheel = "Gwynnda") |>
  mutate(year=as.character(year)) |>
  filter(!is.na(dumpster)) |>
  relocate(trash_wheel)
```

### Combining dataset

``` r
total_trash_df = 
  bind_rows(mr_trash_df,prof_trash_df,Gwy_trash_df) |>
  janitor::clean_names()
```

### Data description

The dataset contains observations on 1032 three different datasets. The
data includes 15 variables, including month, year, different types of
trash (plastic bottles, polystyrene, cigarette butts, glass bottle,
plastic bags,wrappers,sports ball, and homes powered), also weight, and
volume. The total weight of trash collected by Professor Trash Wheel is
246.74. The total number of cigarette butts collected by Gwynnda in June
of 2022 is 18120.

### Calculation

``` r
sum(pull(prof_trash_df,weight_tons),na.rm = TRUE)
```

    ## [1] 246.74

``` r
total_trash_df |>
  filter(trash_wheel == "Gwynnda", month == "June", year == "2022") |>
  summarise(total_cig_butts_Gwy = sum(cigarette_butts, na.rm = TRUE))
```

    ## # A tibble: 1 × 1
    ##   total_cig_butts_Gwy
    ##                 <dbl>
    ## 1               18120

## Problem 3

### Importing three datasets

``` r
bakers_df = 
  read_csv("gbb_datasets/bakers.csv", na = c("NA",".",""))|>
  janitor::clean_names()|>
  rename(name = baker_name) |>
  rename(age = baker_age) |>
  rename(occupation = baker_occupation) |>
  mutate(series = as.character(series)) |>
  mutate(first_name = word(name, 1))
```

    ## Rows: 120 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker Name, Baker Occupation, Hometown
    ## dbl (2): Series, Baker Age
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
bakes_df = 
  read_csv("gbb_datasets/bakes.csv",na = c("NA",".","")) |>
  janitor::clean_names() |>
  mutate(baker = str_replace_all(baker, '"', "")) |>
  relocate(baker) |>
  rename(name = baker) |>
  rename(signature = signature_bake) |>
  mutate(series = as.character(series)) |>
  mutate(episode =as.character(episode))|>
  arrange(name)
```

    ## Rows: 548 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker, Signature Bake, Show Stopper
    ## dbl (2): Series, Episode
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
results_df = 
  read_csv("gbb_datasets/results.csv",na = c("NA",".",""),skip=2) |>
  janitor::clean_names() |>
  mutate(episode = as.character(episode))|>
  mutate(baker = str_replace_all(baker, "Joanne", "Jo")) |>
  rename(name = baker) |>
  mutate(series = as.character(series)) 
```

    ## Rows: 1136 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (2): baker, result
    ## dbl (3): series, episode, technical
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

### Checking completness and correctness

``` r
missing_bakers_in_bake_df = 
  anti_join(bakers_df, bakes_df, by=c("first_name"="name","series"))
missing_brakers_in_results_df =
  anti_join(bakers_df, results_df, by=c("name","series"))
```

### Merging datasets

``` r
merged_df = 
  bakers_df |>
  left_join(results_df, by = c("first_name"="name", "series")) |>
  left_join(bakes_df, by = c("first_name" = "name", "series", 
                               "episode"))
write.csv(merged_df,"merged_cleaned_result.csv",row.names = FALSE )
```

Description: I first imported three datasets. First i imported the
baker.csv from the working directory “gbb_datasets”, and treated the
values “NA”, “.”, and “” as missing data (NA values). I used
janitor::clean_names to clean the column names by converting them to
snake_case, making them lowercase, and removing special characters or
spaces. Then I rename baker_name to name, baker_age to age,
baker_occupation to occupation which helps me to understand. Because in
the original dataset, series is a double variable, so i converted it
into character variable. I also created a new column “first_name”. I
used word function to extract the first row from the name.

Then i imported the bakes.csv from the working directory “gbb_datasets”,
and treated the values “NA”, “.”, and “” as missing data (NA values). I
used janitor::clean_names to clean the column names by converting them
to snake_case, making them lowercase, and removing special characters or
spaces. Then I modify baker column to replace all occurrences of the
double quote variables, and remove it to the first row. I rename name
and signature variables, and converted series and episode into character
variables. Then making name alphabetically. I converted variables
because I met problems when I first try to merge without converting them
into same level.

I used the same way to clean the results.csv. One different was that I
used mutate function to people who named “Joanne” with “Jo”.

I used left_join to merge three dataset by matching “first name” with
“name”,“series” with “series”, “episode” with “episode”. Then I used
write.csv to import the table. In the final dataset, it contains
observation 1136 with 11 columns. Bakers’ name are in alphabetical
order. Key variables are hometown, series, episode, occupation,
signature, and their final result (in or out of the competition).

### Create a reader-friendly table

``` r
star_bakers_df = 
  merged_df |>
  filter(series >= 5) |>
  filter(result %in% c("WINNER","STAR BAKER")) |>
  select(name, series, episode, result)
```

Comments: Candince is not a surprising winner. She showed up on 10
episode in series 7, which means she is very good/talented at baking.
Nadiya is also a predictable winner because she showed up 9 episodes in
series 6, as well as Sophie. Rahul gives surprise because he does not
show up as much as other winners do.

### Importing viewer.csv

``` r
viewer_df = 
  read_csv("gbb_datasets/viewers.csv",na = c("NA",".","")) |>
  janitor::clean_names() |>
  pivot_longer(
    series_1:series_10,
    names_to = "series",
    values_to = "viewship") |>
    head(10)
```

    ## Rows: 10 Columns: 11
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (11): Episode, Series 1, Series 2, Series 3, Series 4, Series 5, Series ...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
view_df = 
  read_csv("gbb_datasets/viewers.csv",na = c("NA",".","")) |>
  janitor::clean_names()
```

    ## Rows: 10 Columns: 11
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (11): Episode, Series 1, Series 2, Series 3, Series 4, Series 5, Series ...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
  mean(pull(view_df,"series_1"),na.rm = TRUE) 
```

    ## [1] 2.77

``` r
  mean(pull(view_df,"series_5"),na.rm = TRUE) 
```

    ## [1] 10.0393

The average viewership in Season 1 is 2.77, Season 5 is 10.0393.
